{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinement and G-Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "from data.uci_datasets import UCIData\n",
    "from main import set_seed, get_device\n",
    "from util.plots import plot_data, plot_regression, plot_bayesian_regression\n",
    "from models.nets import create_mlp\n",
    "from trainer import ModelTrainer, NegativeLogLikelihood\n",
    "\n",
    "from laplace import Laplace\n",
    "\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import BatchGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "try:\n",
    "    initialize(version_base=None, config_path=\"configuration\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "config = compose(config_name=\"uci.yaml\")\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refined Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_nn(model):\n",
    "    weights = []\n",
    "    for name, param in model.named_parameters():\n",
    "        weights.append(param.detach().flatten())\n",
    "    return torch.cat(weights, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RefinedLaplace Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinedLaplace(nn.Module):\n",
    "    def __init__(self, model, output_dim, posterior_covariance):\n",
    "        super(RefinedLaplace, self).__init__()\n",
    "        self.model = model\n",
    "        self.output_dim = output_dim\n",
    "        self.weights_map = flatten_nn(self.model)\n",
    "        self.weights = torch.nn.Parameter(torch.zeros_like(self.weights_map), requires_grad=True)\n",
    "        self.posterior_covariance = posterior_covariance\n",
    "\n",
    "    def forward(self, X):\n",
    "        with torch.no_grad():\n",
    "            f = self.model(X)\n",
    "        J = self._jacobian(X) \n",
    "        out = torch.einsum(\"ijk,k->ij\", J, (self.weights - self.weights_map))\n",
    "        return out\n",
    "    \n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            f = self.model(X)\n",
    "        J = self._jacobian(X)\n",
    "        mean = torch.einsum(\"ijk,k->ij\", J, (self.weights - self.weights_map)) + f\n",
    "        return mean, self._functional_variance(J)\n",
    "        \n",
    "    def _functional_variance(self, Js):\n",
    "        return torch.einsum('ncp,pq,nkq->nck', Js, self.posterior_covariance, Js)\n",
    " \n",
    "\n",
    "    def _jacobian(self, X):\n",
    "        \"\"\"\n",
    "        Compute the jacobian of the model with respect to the input X\n",
    "        Args:\n",
    "            X: input tensor\n",
    "        Returns:\n",
    "            J: jacobian of the model with respect to X\n",
    "        \"\"\"\n",
    "        model = copy.deepcopy(self.model)\n",
    "        model.eval()\n",
    "        model = extend(model)\n",
    "        Js = []\n",
    "        for o in range(self.output_dim):\n",
    "            f = model(X)\n",
    "            f_o = f.sum(dim=0)[o]\n",
    "\n",
    "            with backpack(BatchGrad()):\n",
    "                f_o.backward()\n",
    "            Jo = []\n",
    "            for name, param in model.named_parameters():    \n",
    "                batch_size = param.grad_batch.size(0)\n",
    "                Jo.append(param.grad_batch.reshape(batch_size, -1))\n",
    "            Jo = torch.cat(Jo, dim=1)\n",
    "            Js.append(Jo)\n",
    "        return torch.stack(Js, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer for refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(y, mu, std):\n",
    "    dist = Normal(mu.squeeze(), std.squeeze())\n",
    "    log_probs = dist.log_prob(y.squeeze())\n",
    "    return log_probs.squeeze().sum().item()\n",
    "\n",
    "def evaluate_predictive(model, sigma, dataloader, device):\n",
    "    ll = 0.0\n",
    "    count = 0\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        f_mu, f_var = model.predict(X)\n",
    "        f_sigma = torch.sqrt(f_var)\n",
    "        pred_std = torch.sqrt(f_sigma**2 + sigma**2)\n",
    "        ll += log_likelihood(y, f_mu, pred_std)\n",
    "        count += X.shape[0]\n",
    "    return -ll / count\n",
    "\n",
    "def evaluate(model, sigma, dataloader, device):\n",
    "    model.eval()\n",
    "    criteria = NegativeLogLikelihood(sigma=sigma).to(device)\n",
    "    err = 0.0\n",
    "    nll = 0.0\n",
    "    count = 0\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        batch_size = X.shape[0]\n",
    "        out = model(X)\n",
    "        loss = criteria(out, y).mean()\n",
    "        err += F.mse_loss(out, y, reduction=\"mean\").sqrt().item() * batch_size\n",
    "        nll += loss.item() * batch_size\n",
    "        count += batch_size\n",
    "\n",
    "    nll = nll / count\n",
    "    err = err / count\n",
    "\n",
    "    return nll, err\n",
    "\n",
    "def train(model, sigma, train_dataloader, val_dataloader, epochs, lr, device):\n",
    "    criteria = NegativeLogLikelihood(sigma=sigma).to(device)\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-3\n",
    "    )\n",
    "    best_val_nll = math.inf\n",
    "    best_model = copy.deepcopy(model)\n",
    "    for i in range(epochs):\n",
    "        epoch_err = 0.0\n",
    "        epoch_nll = 0.0\n",
    "        count = 0\n",
    "        model.train()\n",
    "        for X, y in train_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X)\n",
    "            loss = criteria(out, y).mean()    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_size = X.shape[0]\n",
    "            epoch_err += (\n",
    "                F.mse_loss(out, y, reduction=\"mean\").sqrt().item() * batch_size\n",
    "            )\n",
    "            epoch_nll += loss * batch_size\n",
    "            count += batch_size\n",
    "\n",
    "        epoch_nll = epoch_nll / count\n",
    "        epoch_err = epoch_err / count\n",
    "        val_nll, val_err = evaluate(model, sigma, val_dataloader, device)\n",
    "        print(f\"Epoch {i} | Train NLL {epoch_nll} | Val NLL {val_nll} | Train Err {epoch_err} | Val Err {val_err}\")\n",
    "        if val_nll < best_val_nll:\n",
    "            best_val_nll = val_nll\n",
    "            best_model = copy.deepcopy(model)\n",
    "            \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a MAP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = UCIData(config.data.path)\n",
    "meta_data = data.get_metadata()\n",
    "device = get_device()\n",
    "train_dataloader, val_dataloader, test_dataloader = data.get_dataloaders(\n",
    "        dataset=config.data.name,\n",
    "        batch_size=config.trainer.batch_size,\n",
    "        seed=config.data.seed,\n",
    "        val_size=config.data.val_size,\n",
    "        split_index=config.data.split_index,\n",
    "        gap=(config.data.split == \"GAP\"),\n",
    "    )\n",
    "trainer = ModelTrainer(config.trainer, device=device)\n",
    "  \n",
    "\n",
    "model = create_mlp(\n",
    "        input_size=meta_data[config.data.name][\"input_dim\"],\n",
    "        hidden_sizes=config.model.hidden_sizes,\n",
    "        output_size=meta_data[config.data.name][\"output_dim\"],\n",
    "    )\n",
    "model = model.to(device=device, dtype=torch.float64)\n",
    "map_model, sigma = trainer.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma: 0.8317832946777344\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sigma: {sigma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Full Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2589254117941673, 2.113489039836647, 3.548133892335755, 5.956621435290105, 10.0, 12.91549665014884, 16.68100537200059, 21.544346900318832, 27.825594022071243, 35.938136638046274, 46.41588833612777, 59.94842503189409, 77.4263682681127, 100.0]\n"
     ]
    }
   ],
   "source": [
    "prior_precisions = np.logspace(0.1, 1, num=5, base=10).tolist()[:-1]  + np.logspace(1, 2, num=10, base=10).tolist()\n",
    "print(prior_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = copy.deepcopy(map_model)\n",
    "la, prior_precision = trainer.train_la_posthoc(\n",
    "                model=model_copy,\n",
    "                dataloader=train_dataloader,\n",
    "                subset_of_weights=\"all\",\n",
    "                hessian_structure=\"full\",\n",
    "                sigma_noise=sigma,\n",
    "                prior_mean=config.trainer.la.prior_mean,\n",
    "                val_dataloader=val_dataloader,\n",
    "                prior_precisions=prior_precisions\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior precision: 1.2589254117941673\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prior precision: {prior_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_covariance = la.posterior_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.194492605829851"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate_la(la, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_model = RefinedLaplace(model=map_model,\n",
    "                               output_dim=meta_data[config.data.name][\"output_dim\"],\n",
    "                               posterior_covariance=posterior_covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train NLL 2.4769889737858457 | Val NLL 1.8623681159938474 | Train Err 1.5355783060680324 | Val Err 1.2330339568063664\n",
      "Epoch 1 | Train NLL 1.5441986114641064 | Val NLL 1.4355004532004103 | Train Err 1.0433150608894655 | Val Err 0.9670491602586828\n",
      "Epoch 2 | Train NLL 1.300132511783717 | Val NLL 1.3569355092849302 | Train Err 0.8768703022241799 | Val Err 0.9046331779103822\n",
      "Epoch 3 | Train NLL 1.2357285485155862 | Val NLL 1.3343883862477828 | Train Err 0.8278709444027009 | Val Err 0.9014073422692865\n",
      "Epoch 4 | Train NLL 1.2113723467913728 | Val NLL 1.3266603038351388 | Train Err 0.8053017242881769 | Val Err 0.8981457233481793\n",
      "Epoch 5 | Train NLL 1.19807636724184 | Val NLL 1.3230576910030107 | Train Err 0.794409555199651 | Val Err 0.9003190934179299\n",
      "Epoch 6 | Train NLL 1.1902159051901 | Val NLL 1.3238812711760704 | Train Err 0.7859532554273452 | Val Err 0.8961980483405776\n",
      "Epoch 7 | Train NLL 1.1837655967577507 | Val NLL 1.321297641962328 | Train Err 0.780691547110708 | Val Err 0.8944608171001868\n",
      "Epoch 8 | Train NLL 1.1787358843279547 | Val NLL 1.3204291934311283 | Train Err 0.7775240229664815 | Val Err 0.8922809317474076\n",
      "Epoch 9 | Train NLL 1.1741374877870618 | Val NLL 1.319305983000133 | Train Err 0.7724868033912629 | Val Err 0.8950526346564506\n",
      "Epoch 10 | Train NLL 1.1709484449460044 | Val NLL 1.3214008511211177 | Train Err 0.770648765217846 | Val Err 0.8975575363292145\n",
      "Epoch 11 | Train NLL 1.1685196268467175 | Val NLL 1.319981532591196 | Train Err 0.7657086101382247 | Val Err 0.8802199700646183\n",
      "Epoch 12 | Train NLL 1.1646297658062224 | Val NLL 1.3202255238332967 | Train Err 0.761076225125116 | Val Err 0.8968594701199253\n",
      "Epoch 13 | Train NLL 1.1621867248145072 | Val NLL 1.3204885776966881 | Train Err 0.7586649025179895 | Val Err 0.8942276579367494\n",
      "Epoch 14 | Train NLL 1.1594574543222385 | Val NLL 1.31950561413382 | Train Err 0.7579812229410827 | Val Err 0.8967339980773839\n",
      "Epoch 15 | Train NLL 1.158032886308671 | Val NLL 1.3177901362207334 | Train Err 0.7589561804753497 | Val Err 0.885121018546844\n",
      "Epoch 16 | Train NLL 1.1575454098825526 | Val NLL 1.3158158562330438 | Train Err 0.7568436156022895 | Val Err 0.8879742423991877\n",
      "Epoch 17 | Train NLL 1.155073145305879 | Val NLL 1.3175449884083932 | Train Err 0.7567744171981197 | Val Err 0.8830250407869925\n",
      "Epoch 18 | Train NLL 1.1535175436463643 | Val NLL 1.3215542230408635 | Train Err 0.7531604251063739 | Val Err 0.8921168703401355\n",
      "Epoch 19 | Train NLL 1.151694648627382 | Val NLL 1.3189214209330158 | Train Err 0.7536796507401318 | Val Err 0.8889952081880609\n",
      "Epoch 20 | Train NLL 1.1500292989419985 | Val NLL 1.318607274409939 | Train Err 0.7521762225584548 | Val Err 0.8869050739518614\n",
      "Epoch 21 | Train NLL 1.1480686419364654 | Val NLL 1.3185812034079178 | Train Err 0.750458229660486 | Val Err 0.8871555899843904\n",
      "Epoch 22 | Train NLL 1.1481637809881715 | Val NLL 1.3208970699398284 | Train Err 0.7506511536671642 | Val Err 0.8859338499260233\n",
      "Epoch 23 | Train NLL 1.1461581352537913 | Val NLL 1.3207358341478719 | Train Err 0.7498759462225709 | Val Err 0.8867991915434409\n",
      "Epoch 24 | Train NLL 1.1445206022881935 | Val NLL 1.3181200867541538 | Train Err 0.7447726304402692 | Val Err 0.8910751952725618\n",
      "Epoch 25 | Train NLL 1.1441641371705973 | Val NLL 1.3186102112588733 | Train Err 0.743323555953515 | Val Err 0.895614151141337\n",
      "Epoch 26 | Train NLL 1.143509278422132 | Val NLL 1.3170615236498378 | Train Err 0.7437242161796015 | Val Err 0.8860115860590598\n",
      "Epoch 27 | Train NLL 1.1418851865912154 | Val NLL 1.3183795979037294 | Train Err 0.7433322282339038 | Val Err 0.8919480268957405\n",
      "Epoch 28 | Train NLL 1.1409917511020449 | Val NLL 1.3199917480530914 | Train Err 0.7430489368613878 | Val Err 0.8958062105525731\n",
      "Epoch 29 | Train NLL 1.1425892180731878 | Val NLL 1.321286779824454 | Train Err 0.7453980396924674 | Val Err 0.885191606615667\n",
      "Epoch 30 | Train NLL 1.1413726269796423 | Val NLL 1.3178270464164488 | Train Err 0.742792274080979 | Val Err 0.8884616664573257\n",
      "Epoch 31 | Train NLL 1.1394786050356982 | Val NLL 1.3187326173363918 | Train Err 0.7426179495239357 | Val Err 0.8898200742628322\n",
      "Epoch 32 | Train NLL 1.1387200059851588 | Val NLL 1.319190159795883 | Train Err 0.7395256089318492 | Val Err 0.878071171554349\n",
      "Epoch 33 | Train NLL 1.1387379770949693 | Val NLL 1.3191519356025676 | Train Err 0.7429534662903587 | Val Err 0.8869823254360694\n",
      "Epoch 34 | Train NLL 1.138774656642508 | Val NLL 1.3209205688363335 | Train Err 0.7427840879467236 | Val Err 0.887852942586359\n",
      "Epoch 35 | Train NLL 1.136673818955844 | Val NLL 1.317501614909503 | Train Err 0.7354004829224665 | Val Err 0.8910541512981477\n",
      "Epoch 36 | Train NLL 1.1355665196389235 | Val NLL 1.31745182343755 | Train Err 0.7363695281323585 | Val Err 0.8830823621563396\n",
      "Epoch 37 | Train NLL 1.134882562978363 | Val NLL 1.3189918986794982 | Train Err 0.7367356961391692 | Val Err 0.8859223025467139\n",
      "Epoch 38 | Train NLL 1.1343590292420125 | Val NLL 1.3192432170599142 | Train Err 0.7374095685455526 | Val Err 0.892591112813169\n",
      "Epoch 39 | Train NLL 1.134198822718539 | Val NLL 1.3183173919508604 | Train Err 0.7373433463560043 | Val Err 0.8945887726356904\n",
      "Epoch 40 | Train NLL 1.1335155372635377 | Val NLL 1.317350581405253 | Train Err 0.7330865408676742 | Val Err 0.8736612689585089\n",
      "Epoch 41 | Train NLL 1.1330442713815518 | Val NLL 1.3180826928211815 | Train Err 0.7355539295492938 | Val Err 0.878985772285563\n",
      "Epoch 42 | Train NLL 1.132632172419388 | Val NLL 1.3182372005968526 | Train Err 0.7349639113789176 | Val Err 0.8828532390448843\n",
      "Epoch 43 | Train NLL 1.1314754113452639 | Val NLL 1.3163932768682682 | Train Err 0.7335867062325686 | Val Err 0.8855186785591672\n",
      "Epoch 44 | Train NLL 1.1344542388932402 | Val NLL 1.31716149535292 | Train Err 0.7386540072637419 | Val Err 0.8910177074698848\n",
      "Epoch 45 | Train NLL 1.1304507040659728 | Val NLL 1.31741156356058 | Train Err 0.732608061587688 | Val Err 0.8910999738925457\n",
      "Epoch 46 | Train NLL 1.1303074578338326 | Val NLL 1.3193263968378526 | Train Err 0.7294053516809411 | Val Err 0.8887868644469228\n",
      "Epoch 47 | Train NLL 1.1312173451499479 | Val NLL 1.3171625744294504 | Train Err 0.7338410590951968 | Val Err 0.8943107157332734\n",
      "Epoch 48 | Train NLL 1.1298826170698444 | Val NLL 1.3174980111055874 | Train Err 0.7324602471735362 | Val Err 0.8869057529253993\n",
      "Epoch 49 | Train NLL 1.1282440387165005 | Val NLL 1.3178222040411303 | Train Err 0.732377338353551 | Val Err 0.8936202952717673\n",
      "Epoch 50 | Train NLL 1.1287433996044718 | Val NLL 1.3182803579437419 | Train Err 0.7332952564844384 | Val Err 0.8817591088725552\n",
      "Epoch 51 | Train NLL 1.12845622120676 | Val NLL 1.316979123596151 | Train Err 0.7311516514236238 | Val Err 0.8903482329448659\n",
      "Epoch 52 | Train NLL 1.1271773169819146 | Val NLL 1.3168444850677143 | Train Err 0.7291506677309867 | Val Err 0.8867151287030405\n",
      "Epoch 53 | Train NLL 1.1275419622969287 | Val NLL 1.31946413911205 | Train Err 0.7297307266592535 | Val Err 0.8904783710915396\n",
      "Epoch 54 | Train NLL 1.1268809034363643 | Val NLL 1.31937781680423 | Train Err 0.7286874763888508 | Val Err 0.8850430531664655\n",
      "Epoch 55 | Train NLL 1.1263615146470942 | Val NLL 1.3189957189273285 | Train Err 0.7288016649990736 | Val Err 0.8939780628878103\n",
      "Epoch 56 | Train NLL 1.126139206365118 | Val NLL 1.3181751941319557 | Train Err 0.7270371560437279 | Val Err 0.8907853373791131\n",
      "Epoch 57 | Train NLL 1.12579885798331 | Val NLL 1.3187164982993864 | Train Err 0.7278355607667902 | Val Err 0.892443598773165\n",
      "Epoch 58 | Train NLL 1.1260049171209379 | Val NLL 1.3176993609663137 | Train Err 0.7289666207922618 | Val Err 0.8888867510188712\n",
      "Epoch 59 | Train NLL 1.1252535064277238 | Val NLL 1.3167396749989366 | Train Err 0.7271678339880434 | Val Err 0.8872327187328989\n",
      "Epoch 60 | Train NLL 1.1242911444133301 | Val NLL 1.3177224805959975 | Train Err 0.7268734659063565 | Val Err 0.882902427065768\n",
      "Epoch 61 | Train NLL 1.1243219870144692 | Val NLL 1.3171428445466833 | Train Err 0.7257247055820188 | Val Err 0.8846535728992476\n",
      "Epoch 62 | Train NLL 1.1245097683772154 | Val NLL 1.3166750870671957 | Train Err 0.7276136415710999 | Val Err 0.8831753131078244\n",
      "Epoch 63 | Train NLL 1.1240818180020147 | Val NLL 1.3186479442781491 | Train Err 0.7285861184682666 | Val Err 0.8928465912361921\n",
      "Epoch 64 | Train NLL 1.1239538166354988 | Val NLL 1.3194918871876002 | Train Err 0.7289386891026011 | Val Err 0.893989877512663\n",
      "Epoch 65 | Train NLL 1.122754194830019 | Val NLL 1.3163127856328956 | Train Err 0.7266336189006952 | Val Err 0.881943414888694\n",
      "Epoch 66 | Train NLL 1.1233473753288552 | Val NLL 1.3183461384497432 | Train Err 0.7255452092789523 | Val Err 0.8808151984377899\n",
      "Epoch 67 | Train NLL 1.1224233952198166 | Val NLL 1.3168152871185734 | Train Err 0.7286907467965162 | Val Err 0.8853892005239961\n",
      "Epoch 68 | Train NLL 1.1231579461087804 | Val NLL 1.3163034265773124 | Train Err 0.7261292215653117 | Val Err 0.875876922545269\n",
      "Epoch 69 | Train NLL 1.1216384376727189 | Val NLL 1.316503957358002 | Train Err 0.7265297915485043 | Val Err 0.8787593148301794\n",
      "Epoch 70 | Train NLL 1.1209609609314075 | Val NLL 1.3172371517612316 | Train Err 0.7229055309263819 | Val Err 0.8807146206812859\n",
      "Epoch 71 | Train NLL 1.121183929412387 | Val NLL 1.3184291796950067 | Train Err 0.7221192408900752 | Val Err 0.8758715160554881\n",
      "Epoch 72 | Train NLL 1.1218913818264702 | Val NLL 1.31833509196445 | Train Err 0.7247080317459096 | Val Err 0.8897650096993641\n",
      "Epoch 73 | Train NLL 1.1205535585676927 | Val NLL 1.3163909106463383 | Train Err 0.723735782782263 | Val Err 0.8880391576530676\n",
      "Epoch 74 | Train NLL 1.1200075068494781 | Val NLL 1.3178725993389435 | Train Err 0.7250756590895612 | Val Err 0.8830549663852454\n",
      "Epoch 75 | Train NLL 1.120478202743823 | Val NLL 1.318235107115326 | Train Err 0.7191581534955022 | Val Err 0.8844165449323671\n",
      "Epoch 76 | Train NLL 1.1193304473435066 | Val NLL 1.3197972321902216 | Train Err 0.7202654706847008 | Val Err 0.8905347240476552\n",
      "Epoch 77 | Train NLL 1.1192219093404592 | Val NLL 1.3193905441188802 | Train Err 0.7184984405745812 | Val Err 0.8838186253984834\n",
      "Epoch 78 | Train NLL 1.1188759853341936 | Val NLL 1.3184326546963112 | Train Err 0.7224713746439276 | Val Err 0.8777531483655415\n",
      "Epoch 79 | Train NLL 1.1184845566658856 | Val NLL 1.319218318922019 | Train Err 0.7229164622982583 | Val Err 0.8805434304988334\n",
      "Epoch 80 | Train NLL 1.1183204585917617 | Val NLL 1.3204499408743915 | Train Err 0.7207962808363289 | Val Err 0.8882581930575394\n",
      "Epoch 81 | Train NLL 1.118194471162051 | Val NLL 1.3192011175520748 | Train Err 0.7229926440088573 | Val Err 0.890031025722161\n",
      "Epoch 82 | Train NLL 1.1189966148866786 | Val NLL 1.318458117427986 | Train Err 0.7224382920768486 | Val Err 0.8925095014672896\n",
      "Epoch 83 | Train NLL 1.1175110021200567 | Val NLL 1.3173321578976358 | Train Err 0.7228566313290674 | Val Err 0.8829445063912907\n",
      "Epoch 84 | Train NLL 1.1179950356037176 | Val NLL 1.321318560381208 | Train Err 0.7181123737590552 | Val Err 0.8967247078401305\n",
      "Epoch 85 | Train NLL 1.1173281254628216 | Val NLL 1.3211059028098016 | Train Err 0.7207529231945229 | Val Err 0.8874661652301579\n",
      "Epoch 86 | Train NLL 1.1168440436572802 | Val NLL 1.319506304307575 | Train Err 0.7202438305299114 | Val Err 0.8806513836959643\n",
      "Epoch 87 | Train NLL 1.116725929122154 | Val NLL 1.3205722218879354 | Train Err 0.7185540450495576 | Val Err 0.88454441758934\n",
      "Epoch 88 | Train NLL 1.1164288884940659 | Val NLL 1.3200622434018057 | Train Err 0.7190761282599589 | Val Err 0.8880308364404584\n",
      "Epoch 89 | Train NLL 1.1168180134554633 | Val NLL 1.3180170739256007 | Train Err 0.7201450960872017 | Val Err 0.89026933380624\n",
      "Epoch 90 | Train NLL 1.1156812947105699 | Val NLL 1.3200048398878421 | Train Err 0.717595005467094 | Val Err 0.8885581951920308\n",
      "Epoch 91 | Train NLL 1.1160230121581651 | Val NLL 1.3201294876155703 | Train Err 0.7211202677323963 | Val Err 0.886838723233761\n",
      "Epoch 92 | Train NLL 1.1155263788181913 | Val NLL 1.319586149240597 | Train Err 0.7195659510538195 | Val Err 0.8871944600724044\n",
      "Epoch 93 | Train NLL 1.1152813693947223 | Val NLL 1.3197564525841887 | Train Err 0.7185261880869708 | Val Err 0.883717092913119\n",
      "Epoch 94 | Train NLL 1.1155093332438248 | Val NLL 1.3196032194605547 | Train Err 0.7200530063464602 | Val Err 0.891941034276328\n",
      "Epoch 95 | Train NLL 1.1152726097850325 | Val NLL 1.3190728854594462 | Train Err 0.7191640979539485 | Val Err 0.8911509072563356\n",
      "Epoch 96 | Train NLL 1.114535026825853 | Val NLL 1.3214144646090529 | Train Err 0.7182201591839218 | Val Err 0.8790675860626493\n",
      "Epoch 97 | Train NLL 1.1142668433935408 | Val NLL 1.3194375278800703 | Train Err 0.7181699579855441 | Val Err 0.8890418357988726\n",
      "Epoch 98 | Train NLL 1.1140208182166091 | Val NLL 1.3206757459669518 | Train Err 0.7171668108665277 | Val Err 0.8962712724040451\n",
      "Epoch 99 | Train NLL 1.1142723629156148 | Val NLL 1.3214011333376068 | Train Err 0.716716752133496 | Val Err 0.8984238582295327\n"
     ]
    }
   ],
   "source": [
    "refined_model = train(model=refined_model, sigma=sigma, train_dataloader=train_dataloader, val_dataloader=val_dataloader, epochs=100, lr=config.trainer.lr, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4063870995850896"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictive(model=refined_model, sigma=sigma, dataloader=test_dataloader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subnetwork_inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
