{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subnetwork Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "initialize(version_base=None, config_path=\"configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import set_seed\n",
    "import hydra\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from laplace import Laplace\n",
    "from enum import Enum, auto\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from laplace.utils import LargestVarianceDiagLaplaceSubnetMask\n",
    "from strategies.pruning import OBDSubnetMask\n",
    "\n",
    "from hydra.core.config_store import ConfigStore\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from configuration.config import ExperimentConfig\n",
    "from models.nets import create_mlp\n",
    "from data.uci_datasets import UCIData\n",
    "from trainer import ModelTrainer\n",
    "from metrics import nll_bayesian, nll_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1531623411907508\n"
     ]
    }
   ],
   "source": [
    "config = compose(config_name=\"uci.yaml\")\n",
    "set_seed(config.seed)\n",
    "data = UCIData(config.data.path)\n",
    "meta_data = data.get_metadata()\n",
    "\n",
    "   \n",
    "train_dataloader, val_dataloader, test_dataloader = data.get_dataloaders(\n",
    "            dataset=config.data.name,\n",
    "            batch_size=config.trainer.batch_size,\n",
    "            seed=config.data.seed,\n",
    "            val_size=config.data.val_size,\n",
    "            split_index=0,\n",
    "            gap=config.data.gap,\n",
    "        )\n",
    "\n",
    "    \n",
    "model = create_mlp(\n",
    "            input_size=config.model.input_size,\n",
    "            hidden_sizes=config.model.hidden_sizes,\n",
    "            output_size=config.model.output_size,\n",
    "        )\n",
    "model = model.double()\n",
    "\n",
    "trainer = ModelTrainer(config.trainer)\n",
    "\n",
    "map_model, sigma = trainer.train(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            val_dataloader=val_dataloader,\n",
    "        )\n",
    "\n",
    "nll, err, count = trainer.evaluate(\n",
    "            model=map_model, sigma=sigma, dataloader=test_dataloader\n",
    "        )\n",
    "print(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = copy.deepcopy(model)\n",
    "la, prior_precision = trainer.train_la_posthoc(\n",
    "            model=model_copy,\n",
    "            dataloader=train_dataloader,\n",
    "            subset_of_weights=\"all\",\n",
    "            hessian_structure=\"diag\",\n",
    "            sigma_noise=sigma,\n",
    "            prior_mean=config.trainer.la.prior_mean,\n",
    "            val_dataloader=val_dataloader,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0176, 0.0145, 0.0156,  ..., 0.0089, 0.0041, 0.0006],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.posterior_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0176, 0.0145, 0.0156,  ..., 0.0089, 0.0041, 0.0006],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.inv(torch.eye(la.posterior_precision.shape[0]) * la.posterior_precision).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<laplace.utils.matrix.KronDecomposed at 0x2845b5220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.posterior_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = copy.deepcopy(model)\n",
    "la, prior_precision = trainer.train_la_posthoc(\n",
    "            model=model_copy,\n",
    "            dataloader=train_dataloader,\n",
    "            subset_of_weights=\"all\",\n",
    "            hessian_structure=\"kron\",\n",
    "            sigma_noise=sigma,\n",
    "            prior_mean=config.trainer.la.prior_mean,\n",
    "            val_dataloader=val_dataloader,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KronLaplace' object has no attribute 'posterior_variance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m la\u001b[39m.\u001b[39;49mposterior_variance\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KronLaplace' object has no attribute 'posterior_variance'"
     ]
    }
   ],
   "source": [
    "la.posterior_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m I \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(la\u001b[39m.\u001b[39mH\u001b[39m.\u001b[39mto_matrix())\n\u001b[1;32m      2\u001b[0m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39meigvalsh(I)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "I = torch.linalg.inv(la.H.to_matrix())\n",
    "torch.linalg.eigvalsh(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kron(t1, t2):\n",
    "    \"\"\"Computes the Kronecker product between two tensors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t1 : torch.Tensor\n",
    "    t2 : torch.Tensor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kron_product : torch.Tensor\n",
    "    \"\"\"\n",
    "    t1_height, t1_width = t1.size()\n",
    "    t2_height, t2_width = t2.size()\n",
    "    out_height = t1_height * t2_height\n",
    "    out_width = t1_width * t2_width\n",
    "\n",
    "    tiled_t2 = t2.repeat(t1_height, t1_width)\n",
    "    expanded_t1 = (\n",
    "        t1.unsqueeze(2)\n",
    "          .unsqueeze(3)\n",
    "          .repeat(1, t2_height, t2_width, 1)\n",
    "          .view(out_height, out_width)\n",
    "    )\n",
    "\n",
    "    return expanded_t1 * tiled_t2\n",
    "\n",
    "def block_diag(blocks):\n",
    "    \"\"\"Compose block-diagonal matrix of individual blocks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    blocks : list[torch.Tensor]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    M : torch.Tensor\n",
    "    \"\"\"\n",
    "    P = sum([b.shape[0] for b in blocks])\n",
    "    M = torch.zeros(P, P)\n",
    "    p_cur = 0\n",
    "    for block in blocks:\n",
    "        p_block = block.shape[0]\n",
    "        M[p_cur:p_cur+p_block, p_cur:p_cur+p_block] = block\n",
    "        p_cur += p_block\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -3.8579e-07,  1.0005e-06,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 2.1087e-07,  1.0000e+00,  2.5885e-07,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-9.5635e-07, -2.7336e-07,  1.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "         -2.1851e-06,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.8605e-06,\n",
       "          1.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  8.2084e+05]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = list()\n",
    "for Qs, ls, delta in zip(K.eigenvectors, K.eigenvalues, K.deltas):\n",
    "    if len(ls) == 1:\n",
    "        Q, l = Qs[0], ls[0]\n",
    "        blocks.append(Q @ torch.diag(torch.pow(l + delta, 1)) @ Q.T)\n",
    "    else:\n",
    "        Q1, Q2 = Qs\n",
    "        l1, l2 = ls\n",
    "        Q = kron(Q1, Q2)\n",
    "        l = torch.pow(torch.ger(l1, l2) + delta, 1)\n",
    "        L = torch.diag(l.flatten())\n",
    "        B =Q @ L @ Q.T\n",
    "        B = torch.linalg.inv(B)\n",
    "        blocks.append(B)\n",
    "\n",
    "I = block_diag(blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3201, 3201])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "_LinAlgError",
     "evalue": "linalg.inv: The diagonal element 773 is zero, the inversion could not be completed because the input matrix is singular.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_LinAlgError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(la\u001b[39m.\u001b[39;49mH)\n",
      "\u001b[0;31m_LinAlgError\u001b[0m: linalg.inv: The diagonal element 773 is zero, the inversion could not be completed because the input matrix is singular."
     ]
    }
   ],
   "source": [
    "torch.linalg.inv(la.H)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments using UCI gap datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce results using the sub-network selection strategy proposed in Daxberger et al., 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of using pruning methods as a sub-network selection strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of using KFAC approximated sub-network selection strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laplace_regression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
